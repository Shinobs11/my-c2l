{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pickle, torch, logging, typing, numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import transformers as T\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from src.pickleUtils import pdump, pload, pjoin\n",
    "\n",
    "from src.proecssing import correct_count\n",
    "from transformers.models.bert.modeling_bert import SequenceClassifierOutput\n",
    "from src.datasetClasses import DataItem\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_formatter = logging.Formatter('%(asctime)s %(levelname)s %(funcName)s(%(lineno)d) %(message)s')\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "  handler = logging.FileHandler(log_file, mode='w')\n",
    "  handler.setFormatter(log_formatter)\n",
    "  logger = logging.getLogger(name)\n",
    "  logger.setLevel(level)\n",
    "  logger.addHandler(handler)\n",
    "  return logger\n",
    "\n",
    "error_logger = setup_logger(\"error_log\", \"error_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"imdb\"\n",
    "DATASET_PATH = f\"./datasets/{DATASET_NAME}/base\"\n",
    "OUTPUT_PATH = f\"checkpoints/{DATASET_NAME}/model\"\n",
    "TRIPLETS_PATH = f\"./datasets/{DATASET_NAME}/augmented_triplets\"\n",
    "TOPK_NUM = 4\n",
    "\n",
    "\n",
    "import json, psutil\n",
    "env = {}\n",
    "with open(\"./env.json\", mode=\"r\") as f:\n",
    "  env = json.load(f)\n",
    "\n",
    "\n",
    "memAvailable = psutil.virtual_memory().available\n",
    "estimatedMemConsumed = os.path.getsize(os.path.join(DATASET_PATH, \"train_set.pickle.blosc\")) * 3\n",
    "USE_PINNED_MEMORY = True if (env['USE_PINNED_MEMORY'] & (memAvailable > estimatedMemConsumed)) == 1 else False\n",
    "\n",
    "\n",
    "sampling_ratio = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: T.BertTokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "train_set = pload(os.path.join(DATASET_PATH, \"train_set\"))\n",
    "train_texts:list[str] = train_set['review'].tolist()\n",
    "train_labels:list = train_set['sentiment'].tolist()\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True)\n",
    "pdump(train_encodings, os.path.join(DATASET_PATH, \"train_encodings\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_set = pload(os.path.join(DATASET_PATH, \"val_set\"))\n",
    "val_texts:list[str] = val_set['review'].tolist()\n",
    "val_labels: list = val_set['sentiment'].tolist()\n",
    "val_encodings = tokenizer(val_texts, padding=True, truncation=True)\n",
    "pdump(val_encodings, os.path.join(DATASET_PATH, \"val_encodings\"))\n",
    "print(train_encodings.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  src.datasetClasses import IMDBDataset\n",
    "train_dataset = IMDBDataset(labels=train_labels, encodings=train_encodings)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=1,\n",
    "  shuffle=False,\n",
    "  persistent_workers=False, ##Switch to true if dataloader is used multiple times\n",
    "  pin_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model:BertForSequenceClassification = BertForSequenceClassification.from_pretrained(os.path.join(OUTPUT_PATH, 'best_epoch')) #type:ignore\n",
    "model.to(device)\n",
    "def get_gradient_norms(batch):\n",
    "  input_ids:Tensor = batch['input_ids'].to(device)\n",
    "  attention_mask:Tensor = batch['attention_mask'].to(device)\n",
    "  labels:Tensor = batch['labels'].to(device)\n",
    "\n",
    "  _, labels = torch.max(labels, dim=1)\n",
    "\n",
    "\n",
    "  outputs:SequenceClassifierOutput | tuple[Tensor] = model.forward(input_ids=input_ids, attention_mask=attention_mask, labels=labels, return_dict=True)\n",
    "  assert isinstance(outputs, SequenceClassifierOutput)\n",
    "  \n",
    "  loss = outputs['loss']\n",
    "  loss.backward(retain_graph=True)\n",
    "  torch.cuda.empty_cache()\n",
    "  importances = torch.tensor([]).to(device)\n",
    "  for pos_index, token_index in zip(range(1, len(input_ids[0])), input_ids[0][1:]):\n",
    "    if token_index == tokenizer.sep_token_id:\n",
    "      break\n",
    "    importance = torch.norm(model.bert.embeddings.position_embeddings.weight.grad[pos_index], 2).float().detach() #type:ignore\n",
    "    importances = torch.cat((importances, importance.unsqueeze(0)), dim=-1)\n",
    "  \n",
    "  model.bert.embeddings.position_embeddings.weight.grad = None #! why???\n",
    "\n",
    "  return importances\n",
    "\n",
    "def compute_importances(data_loader:DataLoader, importance_function:typing.Callable) -> list[Tensor]:\n",
    "  all_importances: list = []\n",
    "  for batch in tqdm(data_loader):\n",
    "    importances = importance_function(batch)\n",
    "    all_importances.append(importances)\n",
    "  return all_importances\n",
    "\n",
    "def compute_average_importance(data_loader:DataLoader, all_importances) -> list[Tensor]:\n",
    "  all_averaged_importances:list = []\n",
    "  importance_dict = dict()\n",
    "  importance_dict_counter = dict()\n",
    "\n",
    "  for importances, batch in tqdm(zip(all_importances, data_loader)):\n",
    "    tokens = [x for x in batch['input_ids'][0][1:] if x not in [tokenizer.sep_token_id, tokenizer.pad_token_id]]\n",
    "\n",
    "    for token_importance, token in zip(importances, tokens):\n",
    "      if not token in importance_dict.keys():\n",
    "        importance_dict[token.item()] = 0\n",
    "        importance_dict_counter[token.item()] = 0\n",
    "      importance_dict[token.item()] += token_importance\n",
    "      importance_dict_counter[token.item()] += 1\n",
    "    \n",
    "  for importances, batch in tqdm(zip(all_importances, data_loader)):\n",
    "    tokens = [x for x in batch['input_ids'][0][1:] if x not in [tokenizer.sep_token_id, tokenizer.pad_token_id]]\n",
    "    averaged_importances = torch.Tensor([importance_dict[x.item()]/importance_dict_counter[x.item()] for x in tokens])\n",
    "    all_averaged_importances.append(averaged_importances)\n",
    "  return all_averaged_importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancePath = os.path.join(DATASET_PATH, \"train_set_importance\")\n",
    "importance: list[Tensor] = []\n",
    "if(os.path.exists(pjoin(importancePath))):\n",
    "  importance = pload(importancePath)\n",
    "else:\n",
    "  importance = compute_importances(train_loader, get_gradient_norms)\n",
    "  pdump(importance, importancePath)\n",
    "\n",
    "averageImportancePath = os.path.join(DATASET_PATH, \"train_set_average_importance\")\n",
    "averageImportance: list[Tensor] = []\n",
    "if(os.path.exists(pjoin(averageImportancePath))):\n",
    "  averageImportance = pload(averageImportancePath)\n",
    "\n",
    "else:\n",
    "  averageImportance = compute_average_importance(train_loader, importance)\n",
    "  pdump(averageImportance, averageImportancePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlm_model: BertForMaskedLM = BertForMaskedLM.from_pretrained('bert-base-uncased') #type: ignore\n",
    "mlm_model: BertForMaskedLM = mlm_model.to(device) #type: ignore\n",
    "mlm_model.eval()\n",
    "\n",
    "def mask_data(data_loader:DataLoader, all_importances: list[Tensor], sampling_ratio, augment_ratio):\n",
    "  triplets = []\n",
    "  error_count = 0\n",
    "  no_flip_count = 0\n",
    "\n",
    "  no_flip_index = []\n",
    "  for importances, batch in tqdm(zip(all_importances, data_loader)):\n",
    "    label = []\n",
    "    tokens = torch.tensor([x for x in batch['input_ids'][0][1:] if x not in [tokenizer.sep_token_id, tokenizer.pad_token_id]]) # could this be done better?\n",
    "    \n",
    "    assert tokens.size() == importances.size()\n",
    "    orig_sample = tokenizer.decode(tokens)\n",
    "    causal_mask, err_flag, maximum_score = mask_causal_words(tokens.cpu().numpy(), batch, importances.cpu().numpy(), topk=sampling_ratio)\n",
    "    no_flip_index.append(err_flag)\n",
    "    if err_flag:\n",
    "      no_flip_count += 1\n",
    "    \n",
    "    if 1 not in causal_mask:\n",
    "      triplets.append((label, orig_sample, orig_sample, orig_sample, err_flag, maximum_score))\n",
    "      continue\n",
    "\n",
    "    for _ in range(augment_ratio):\n",
    "      causal_masked_tokens = []\n",
    "      noncausal_masked_tokens = []\n",
    "\n",
    "      if sampling_ratio is None:\n",
    "        causal_masked_tokens = [tokens[i] if causal_mask[i] == 0 else tokenizer.mask_token_id for i in range(len(tokens))]\n",
    "        noncausal_masked_tokens = [tokens[i] if causal_mask[i] == 1 else tokenizer.mask_token_id for i in range(len(tokens))]\n",
    "\n",
    "      elif type(sampling_ratio) == int:\n",
    "        causal_indices = np.where(np.array(causal_mask) == 1)[0]\n",
    "        noncausal_indices = np.where(np.array(causal_mask) == 0)[0]\n",
    "\n",
    "        causal_mask_indices = np.random.choice(causal_indices, sampling_ratio)\n",
    "\n",
    "        try:\n",
    "          noncausal_mask_indices = np.random.choice(noncausal_indices, max(1, min(sampling_ratio, len(noncausal_indices))))\n",
    "        except:\n",
    "          noncausal_mask_indices = np.random.choice(causal_indices, sampling_ratio)\n",
    "          error_count += 1\n",
    "\n",
    "        causal_masked_tokens = [tokens[i] if i not in causal_mask_indices else tokenizer.mask_token_id for i in range(len(tokens))]\n",
    "        noncausal_masked_tokens = [tokens[i] if i not in noncausal_mask_indices else tokenizer.mask_token_id for i in range(len(tokens))]\n",
    "      else:\n",
    "        pass\n",
    "\n",
    "      causal_masked_sample = tokenizer.decode(causal_masked_tokens)\n",
    "      noncausal_masked_sample = tokenizer.decode(noncausal_masked_tokens)\n",
    "\n",
    "      _, labels = torch.max(batch['labels'], dim=1)\n",
    "   \n",
    "      if labels[0] == 0: label = [0, 1]\n",
    "      elif labels[0] == 1: label = [1, 0]\n",
    "      triplets.append((label, orig_sample, causal_masked_sample, noncausal_masked_sample, err_flag, maximum_score))\n",
    "  print(f\"Error count: {error_count}\")\n",
    "  print(f\"No flip count: {no_flip_count}\")\n",
    "  return triplets, no_flip_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mask_causal_words(tokens:Tensor, batch:DataItem, importances: Tensor, topk=1):\n",
    "  dropout = torch.nn.Dropout(0.5)\n",
    "  causal_mask = [0 for _ in range(len(tokens))]\n",
    "  all_importance_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "  err_flag = False\n",
    "  find_flag = False\n",
    "\n",
    "  input_ids:Tensor = batch['input_ids'].squeeze().repeat((TOPK_NUM,)).reshape(TOPK_NUM, -1).to(device)\n",
    "  attention_mask:Tensor = batch['attention_mask'].expand(TOPK_NUM, -1).to(device)\n",
    "  token_type_ids:Tensor = batch['token_type_ids'].expand(TOPK_NUM, -1).to(device) #! is token_type_ids actually used anywhere???\n",
    "\n",
    "  masked_input_ids = batch['input_ids'].squeeze().repeat((len(tokens),)).reshape(len(tokens), -1).to(device)\n",
    "  masked_attention_mask = batch['attention_mask'].expand(len(tokens), -1).to(device)\n",
    "  masked_token_type_ids = batch['token_type_ids'].expand(len(tokens), -1).to(device)\n",
    "\n",
    "  fake_labels = torch.ones((len(tokens), ))\n",
    "  \n",
    "  masked_train = IMDBDataset({\n",
    "    'input_ids': masked_input_ids,\n",
    "    'attention_mask': masked_attention_mask,\n",
    "    'token_type_ids': masked_token_type_ids,\n",
    "    'importance_indices': all_importance_indices\n",
    "  }, fake_labels)\n",
    "\n",
    "  masked_train_loader = DataLoader(masked_train, batch_size=4, shuffle=False)\n",
    "  logits = []\n",
    "  for masked_batch in masked_train_loader:\n",
    "    masked_input_ids = masked_batch['input_ids'].to(device) # 4 x 313\n",
    "    masked_attention_mask = masked_batch['attention_mask'].to(device) # 4 x 313\n",
    "    masked_token_type_ids = masked_batch['token_type_ids'].to(device) # 4 x 313\n",
    "    importance_indices = masked_batch['importance_indices'].to(device)# 4\n",
    "    masked_input_embeds: Tensor = mlm_model.bert.embeddings.word_embeddings(masked_input_ids) #4 x 313 x 768\n",
    "\n",
    "    #dropout some of the embeddings at random\n",
    "    for mi_i, topk_i in zip(range(masked_input_embeds.size(0)), importance_indices):\n",
    "      masked_input_embeds[mi_i][topk_i + 1] = dropout(masked_input_embeds[mi_i][topk_i + 1])\n",
    "    \n",
    "    #get predicted words from mlm model given the partially missing embeds\n",
    "    with torch.no_grad():\n",
    "      outputs = mlm_model(attention_mask = masked_attention_mask, token_type_ids = masked_token_type_ids, inputs_embeds = masked_input_embeds)\n",
    "      predictions = outputs[0] # 4 x 313 x 30522, just a casual 38 million numbers. shape(batch_size, sequence_length, config.vocab_size)\n",
    "    \n",
    "    #search through and find top k logits, in this case 4. \n",
    "    topk_logit_indices = torch.topk(predictions, TOPK_NUM, dim=-1)[1] # 4 sequences x 313 tokens x 4 \n",
    "\n",
    "    #for the top k most important tokens, get their respective k candidates\n",
    "    mask_candidates = [topk_logits[importance_index + 1] for importance_index, topk_logits in zip(importance_indices, topk_logit_indices)]\n",
    "\n",
    "    \n",
    "    for importance_index, mask_candidate in zip(importance_indices, mask_candidates):\n",
    "      if importances[importance_index] == 0:\n",
    "        continue\n",
    "      recon_input_ids = input_ids.clone()\n",
    "      for i, mc in enumerate(mask_candidate):\n",
    "        recon_input_ids[i][importance_index + 1] = mc\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        recon_outputs = model(recon_input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        _, recon_prediction = torch.max(recon_outputs[0], dim=1)\n",
    "      if len(torch.unique(recon_prediction)) != 1:\n",
    "        causal_mask[importance_index] = 1\n",
    "        find_flag = True\n",
    "        break\n",
    "\n",
    "\n",
    "    if find_flag:\n",
    "      break\n",
    "\n",
    "    if 1 not in causal_mask:\n",
    "      causal_mask[importance_indices[0]] = 1\n",
    "      err_flag = True\n",
    "      return causal_mask, err_flag, 0\n",
    "  \n",
    "  return causal_mask, err_flag, 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/shino/dev/my-c2l/src/datasetClasses.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} #\n",
      "/home/shino/dev/my-c2l/src/datasetClasses.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n",
      "650it [02:22,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error count: 0\n",
      "No flip count: 607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/imdb/augmented_triplets/augmented_triplets.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[306], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m   os\u001b[39m.\u001b[39mmkdir(TRIPLETS_PATH)\n\u001b[1;32m     15\u001b[0m pdump(triplets_train, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TRIPLETS_PATH, \u001b[39m\"\u001b[39m\u001b[39maugmented_triplets\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(TRIPLETS_PATH, \u001b[39m\"\u001b[39;49m\u001b[39maugmented_triplets.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m   json\u001b[39m.\u001b[39mdump(triplets_train, f)\n\u001b[1;32m     19\u001b[0m \u001b[39m# pr.disable()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# s = io.StringIO()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# sortby = SortKey.CUMULATIVE\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m#608/650 -> 42/650 flips\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m#given that i used about a third of the data to train my model, doesn't surprise me i have a third of the flips\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/my-c2l-HBWGwx8r/lib/python3.11/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/imdb/augmented_triplets/augmented_triplets.json'"
     ]
    }
   ],
   "source": [
    "sampling_ratio = 1\n",
    "augment_ratio = 1\n",
    "\n",
    "\n",
    "\n",
    "# import cProfile, pstats, io\n",
    "# from pstats import SortKey\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "triplets_train, no_flip_idx_train = mask_data(train_loader, averageImportance, sampling_ratio=sampling_ratio, augment_ratio=augment_ratio)\n",
    "\n",
    "if not os.path.exists(TRIPLETS_PATH):\n",
    "  os.mkdir(TRIPLETS_PATH)\n",
    "\n",
    "pdump(triplets_train, os.path.join(TRIPLETS_PATH, \"augmented_triplets\"))\n",
    "with open(os.path.join(TRIPLETS_PATH, \"augmented_triplets.json\"), mode='w') as f:\n",
    "  json.dump(triplets_train, f)\n",
    "\n",
    "# pr.disable()\n",
    "# s = io.StringIO()\n",
    "# sortby = SortKey.CUMULATIVE\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "# print(s.getvalue())\n",
    "\n",
    "#83/100 -> 17/100 flips\n",
    "#608/650 -> 42/650 flips\n",
    "#given that i used about a third of the data to train my model, doesn't surprise me i have a third of the flips\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-c2l-HBWGwx8r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71af0930d805f253c0243b989e31994c440b46a2d46e7ea0e20d5d8c3a1ad7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
